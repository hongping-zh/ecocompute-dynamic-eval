<div align="center">

# âš¡ EcoCompute Dynamic Eval

> **Discovery**: 4-bit quantization wastes 40% more energy on small models

### Compare AI models by Accuracy Ã— Cost Ã— Carbon â€” RTX 5090 benchmarks reveal when quantization hurts efficiency

[![Live Demo](https://img.shields.io/badge/ğŸš€_Try_Demo-Live-brightgreen?style=for-the-badge)](https://hongping-zh.github.io/ecocompute-dynamic-eval/)
[![RTX 5090 Data](https://img.shields.io/badge/ğŸ“Š_RTX_5090-Verified-green?style=for-the-badge)](https://github.com/hongping-zh/ecocompute-ai)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue?style=for-the-badge)](LICENSE)

</div>

---

## ğŸ’¡ Before You Deploy That LLM

**You need to know**:
- âŒ Qwen2-1.5B (NF4) uses **+29% energy** vs FP16
- âœ… Qwen2-7B (NF4) saves **-11% energy** vs FP16  
- ğŸ’° Choosing wrong quantization **wastes $50+/month** in electricity

**Why?** Small models have low compute, so quantization overhead dominates. Industry advice to "just quantize everything" can actually **increase** your carbon footprint.

**Solution**: Use this dashboard to compare **real RTX 5090 measurements** before deployment.

---

## ï¿½ The Quantization Paradox â€” Our Core Discovery

We benchmarked **8 model configurations on NVIDIA RTX 5090 (Blackwell)** with NVML 10 Hz power sampling and found a result that challenges industry assumptions:

```
Energy per 1K tokens (Joules) â€” RTX 5090 Measured Data
                                                                    
  TinyLlama 1.1B   FP16  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 1,659 J                 
                    NF4   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 2,098 J  (+26.5% âš ï¸)
                                                                    
  Qwen2 1.5B       FP16  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 2,411 J         
                    NF4   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 3,120 J  (+29.4% âš ï¸)
                                                                    
  Qwen2.5 3B       FP16  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 3,383 J
                    NF4   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 3,780 J  (+11.7% âš ï¸)
                                                                    
  Qwen2 7B         FP16  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 5,509 J
                    NF4   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 4,878 J  (-11.4% âœ…)
```

> **ğŸ’¡ Key Insight**: 4-bit quantization only saves energy for models **larger than ~5B parameters**. For smaller models, FP16 is actually more energy-efficient. This means the common advice to "just quantize everything" can **increase** your carbon footprint.

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| **ğŸ“Š Dynamic Leaderboard** | Compare 20+ models across accuracy, cost, carbon, and energy efficiency â€” with RTX 5090 provenance badges for verified data |
| **ğŸ§® Emissions Calculator** | 15+ preset templates (chatbot, code review, RAG pipelineâ€¦), sensitivity analysis, break-even charts, and shareable comparison links |
| **âš¡ Live System Monitor** | Real-time GPU power consumption and efficiency visualization with animated charts |
| **âš–ï¸ DeepSeek vs GPT** | Step-by-step workflow to compare cost and carbon impact for your specific workload |
| **ğŸ” Methodology** | Full transparency â€” every data point links to its source, measurement method, and confidence level |
| **ğŸ¤– Multi-API Insights** | Connect Gemini, OpenAI, or Groq for AI-powered analysis â€” or use Demo mode with zero config |

---

## ğŸš€ Quick Start

### Option 1: Live Demo (Zero Setup)

**ğŸ‘‰ [https://hongping-zh.github.io/ecocompute-dynamic-eval/](https://hongping-zh.github.io/ecocompute-dynamic-eval/)**

No installation needed. Works in Demo mode out of the box.

### Option 2: Run Locally

**Prerequisites:** [Node.js](https://nodejs.org/) 18+

```bash
# Clone the repository
git clone https://github.com/hongping-zh/ecocompute-dynamic-eval.git
cd ecocompute-dynamic-eval

# Install dependencies
npm install

# Start development server
npm run dev
```

Open **http://localhost:5173** in your browser. The app runs in Demo mode by default â€” no API keys required.

### Option 3: Configure AI Insights (Optional)

To enable AI-powered model analysis, click **Settings** in the sidebar and add an API key:

| Provider | API Key Required | Notes |
|----------|:----------------:|-------|
| **Demo Mode** | âŒ | Simulated responses, works out of the box |
| **Google Gemini** | âœ… | [Free tier available](https://ai.google.dev/) |
| **OpenAI** | âœ… | GPT-4o model |
| **Groq** | âœ… | Ultra-fast inference |

---

## ğŸ“Š Benchmark Data

All RTX 5090 data was collected under controlled conditions:

| Parameter | Value |
|-----------|-------|
| **Hardware** | NVIDIA GeForce RTX 5090 (32GB GDDR7, Blackwell) |
| **Platform** | AutoDL Cloud Server |
| **Framework** | PyTorch 2.10.0 + CUDA 12.8 |
| **Quantization** | bitsandbytes NF4 |
| **Sampling** | NVML 10 Hz power polling |
| **Runs** | 10 per configuration |
| **Max Tokens** | 256 |

### Models Benchmarked (RTX 5090 Verified)

| Model | FP16 Energy | NF4 Energy | Î” Energy | Monthly Cost Impact* |
|-------|:----------:|:----------:|:--------:|:-------------------:|
| TinyLlama 1.1B | 1,659 J | 2,098 J | **+26.5%** âš ï¸ | +$13/month |
| Qwen2 1.5B | 2,411 J | 3,120 J | **+29.4%** âš ï¸ | +$21/month |
| Qwen2.5 3B | 3,383 J | 3,780 J | **+11.7%** âš ï¸ | +$12/month |
| Qwen2 7B | 5,509 J | 4,878 J | **âˆ’11.4%** âœ… | âˆ’$19/month |

*Based on 1M tokens/month, $0.12/kWh electricity cost

The dashboard also includes estimated data for commercial APIs (GPT-4o, Gemini, Claude) and research models (LLaMA, BERT, ResNet) with clearly labeled confidence levels.

ğŸ“„ **Full benchmark report**: [RTX5090_Energy_Benchmark_Report_EN.md](https://github.com/hongping-zh/ecocompute-ai)

---

## ğŸ“ Project Structure

```
ecocompute-dynamic-eval/
â”‚
â”œâ”€â”€ components/                  # React UI components
â”‚   â”œâ”€â”€ Leaderboard.tsx          #   Dynamic model comparison table with sorting & filters
â”‚   â”œâ”€â”€ Calculator.tsx           #   Emissions calculator with 15+ templates & sensitivity analysis
â”‚   â”œâ”€â”€ AudioMonitor.tsx         #   Real-time GPU power monitoring with animated charts
â”‚   â”œâ”€â”€ DeepSeekVsGpt.tsx        #   Side-by-side cost/carbon workflow comparison
â”‚   â”œâ”€â”€ Methodology.tsx          #   Data sources, formulas, and provenance disclosure
â”‚   â”œâ”€â”€ AITools.tsx              #   Floating AI assistant panel
â”‚   â”œâ”€â”€ ApiCostComparison.tsx    #   API pricing comparison view
â”‚   â”œâ”€â”€ Pricing.tsx              #   Pricing page component
â”‚   â””â”€â”€ SettingsPanel.tsx        #   API provider configuration
â”‚
â”œâ”€â”€ services/                    # Backend service integrations
â”‚   â”œâ”€â”€ geminiService.ts         #   Multi-provider AI API integration (Gemini/OpenAI/Groq)
â”‚   â”œâ”€â”€ engine.ts                #   Calculation engine for emissions & cost
â”‚   â””â”€â”€ types.ts                 #   Service-layer TypeScript types
â”‚
â”œâ”€â”€ constants.ts                 # RTX 5090 benchmark data + commercial API estimates
â”œâ”€â”€ types.ts                     # Shared TypeScript type definitions
â”œâ”€â”€ App.tsx                      # Main app with sidebar navigation & URL routing
â”œâ”€â”€ index.tsx                    # React entry point
â”œâ”€â”€ index.html                   # HTML template
â”œâ”€â”€ index.css                    # Global styles (Tailwind)
â”‚
â”œâ”€â”€ public/                      # Static assets
â”‚   â”œâ”€â”€ robots.txt               #   Search engine directives
â”‚   â””â”€â”€ sitemap.xml              #   Sitemap for SEO
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ FUNDING.yml              # GitHub Sponsors configuration
â”œâ”€â”€ CONTRIBUTING.md              # Contribution guidelines (templates, data, bugs)
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ package.json                 # Dependencies & scripts
â”œâ”€â”€ tsconfig.json                # TypeScript configuration
â””â”€â”€ vite.config.ts               # Vite build configuration
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| **Framework** | React 19 + TypeScript |
| **Build** | Vite 6 |
| **Styling** | Tailwind CSS |
| **Charts** | Recharts 3 |
| **Icons** | Lucide React |
| **AI APIs** | Google Gemini, OpenAI, Groq |
| **Hosting** | GitHub Pages |

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

- **ğŸ§® Submit calculator templates** â€” Share real-world AI workload scenarios
- **ğŸ“Š Contribute benchmark data** â€” Run benchmarks on your GPU and share results
- **ğŸ› Report bugs** â€” Help us improve the dashboard
- **ğŸ’¡ Suggest features** â€” Open an issue tagged `enhancement`

See **[CONTRIBUTING.md](CONTRIBUTING.md)** for detailed guidelines and template submission process.

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

By contributing, you agree that your contributions will be licensed under the same license.

---

## ğŸ”— Related Projects

| Project | Description |
|---------|-------------|
| [**EcoCompute AI**](https://github.com/hongping-zh/ecocompute-ai) | Full RTX 5090 benchmark suite, raw data, and research reports |

---

## ğŸ“¬ Contact

- **Live Demo**: [hongping-zh.github.io/ecocompute-dynamic-eval](https://hongping-zh.github.io/ecocompute-dynamic-eval/)
- **Email**: zhanghongping1982@gmail.com
- **Sponsor**: [GitHub Sponsors](https://github.com/sponsors/hongping-zh)

> **If you're an investor, accelerator, or potential design partner** â€” I'd love to chat. Email me or [open a Discussion](https://github.com/hongping-zh/ecocompute-dynamic-eval/discussions) on the repo.

---

<p align="center">
  <b>ğŸŒ Making AI development more sustainable, one model at a time.</b>
</p>
